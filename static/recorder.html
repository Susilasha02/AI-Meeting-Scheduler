<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Recorder — AI Meeting Scheduler</title>
  <style>
    :root{
      --bg:#f6f8fb; --card:#fff; --accent:#6f46f6; --muted:#6b7280; --radius:14px; --maxwidth:1100px;
    }
    html,body{height:100%;margin:0;font-family:Inter,system-ui,Segoe UI,Roboto,"Helvetica Neue",Arial;background:var(--bg);color:#111}
    .wrap{min-height:100%;display:flex;align-items:center;justify-content:center;padding:32px;box-sizing:border-box}
    .card{width:100%;max-width:var(--maxwidth);background:var(--card);border-radius:var(--radius);padding:28px;box-shadow:0 6px 30px rgba(23,25,33,0.06)}
    .header{display:flex;align-items:center;gap:12px;margin-bottom:16px}
    .logo{width:56px;height:56px;border-radius:10px;background:linear-gradient(135deg,#6f46f6,#b794f4);display:flex;align-items:center;justify-content:center;color:white;font-weight:700;font-size:18px}
    h1{margin:0;font-size:20px}
    p.lead{margin:6px 0 18px;color:var(--muted);font-size:14px}
    .controls{display:flex;gap:12px;align-items:center;margin-bottom:18px}
    button{padding:10px 16px;border-radius:10px;border:0;cursor:pointer;font-weight:600}
    .btn-primary{background:var(--accent);color:white}
    .btn-ghost{background:transparent;color:var(--accent);border:1px solid rgba(111,70,246,0.12)}
    .status{color:var(--muted);font-size:13px}
    .wave{width:100%;height:86px;background:linear-gradient(180deg,#f8fafc,#fff);border-radius:10px;border:1px dashed #e6e9ef;display:flex;align-items:center;justify-content:center;color:#9aa3b2;margin-bottom:18px;padding:12px;box-sizing:border-box}
    .transcript{min-height:80px; max-height:260px; overflow:auto; padding:14px; background:#fafbff; border-radius:10px; border:1px solid #eef2ff; color:#111; font-size:14px; line-height:1.7}
    .muted{color:var(--muted);font-size:13px}
    .row{display:flex;gap:12px;align-items:center}
    a.momlink{color:var(--accent); text-decoration:none; border:1px solid rgba(111,70,246,0.08); padding:8px 12px; border-radius:8px; background:#fff}
    .hint{color:#9aa3b2;font-size:13px;margin-top:8px}
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card" role="main">
      <div class="header">
        <div class="logo">TS</div>
        <div>
          <h1>Meeting Recorder</h1>
          <p class="lead">Automatically records meeting audio and generates transcript / MoM. Auto-starts when possible — click to give microphone permission if required.</p>
        </div>
      </div>

      <div class="controls">
        <button id="btnStart" class="btn-primary">Start Recording</button>
        <button id="btnStop" class="btn-ghost" disabled>Stop</button>
        <div class="status" id="status">Idle</div>
      </div>

      <div class="wave" id="wave">Mic status: waiting for input…</div>

      <div class="muted">Live Transcript</div>
      <div class="transcript" id="transcript">No transcript yet.</div>

      <div style="height:14px;"></div>
      <div class="muted">Upload / Save</div>
      <div style="margin-top:10px; display:flex; gap:10px; align-items:center;">
        <button id="uploadBtn" class="btn-ghost" disabled>Upload Audio & Transcript</button>
        <button id="openMom" class="btn-ghost" style="display:none">Open MoM</button>
      </div>
      <div class="hint" id="momHint" style="margin-top:10px; display:none;"></div>
    </div>
  </div>

<script>
(async function(){
  const statusEl = document.getElementById('status');
  const startBtn  = document.getElementById('btnStart');
  const stopBtn   = document.getElementById('btnStop');
  const wave      = document.getElementById('wave');
  const transcriptEl = document.getElementById('transcript');
  const uploadBtn = document.getElementById('uploadBtn');
  const openMomBtn = document.getElementById('openMom');
  const momHint = document.getElementById('momHint');

  const APP_BASE = (window.APP_BASE_URL || '').replace(/\/$/,'') || location.origin;

  let mediaStream = null, recorder = null, recordedChunks = [];
  let recognition = null;
  let liveTranscript = "";      // single paragraph joined by spaces
  let lastNormalized = "";      // dedupe only if identical
  let lastAddTime = 0;

  // audio constraints optimized for meetings
  const constraints = {
    audio: {
      echoCancellation: true,
      noiseSuppression: true,
      autoGainControl: true,
      channelCount: 1,
      sampleRate: 44100
    }
  };

  function updateStatus(t){ statusEl.textContent = t; }
  function showWave(msg){ wave.textContent = msg; }
  function normalize(s){ return (s||"").trim().toLowerCase().replace(/\s+/g,' '); }

  function appendToParagraph(text){
    if(!text) return;
    const cleaned = text.trim();
    if(!cleaned) return;
    const norm = normalize(cleaned);
    // tiny dedupe: if identical to lastNormalized, ignore
    if(norm === lastNormalized) return;
    // remove repeated immediate words inside the chunk
    const deduped = cleaned.split(' ').filter((w,i,arr) => !(i>0 && arr[i-1]===w)).join(' ');
    if(liveTranscript === "" || liveTranscript === "No transcript yet."){
      liveTranscript = deduped;
    } else {
      // join with space — keep as one paragraph
      liveTranscript = liveTranscript.trim() + " " + deduped;
    }
    lastNormalized = norm;
    transcriptEl.textContent = liveTranscript;
  }

  async function startRecording(){
    updateStatus('Requesting microphone...');
    try{
      mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
    } catch(err){
      updateStatus('Microphone permission required.');
      showWave('Click "Start Recording" to give mic permission.');
      throw err;
    }

    if(recorder){ recorder.stop(); recorder = null; }

    recordedChunks = [];
    recorder = new MediaRecorder(mediaStream, { mimeType: 'audio/webm;codecs=opus' });

    recorder.ondataavailable = e => { if(e.data && e.data.size) recordedChunks.push(e.data); };
    recorder.onstart = () => {
      updateStatus('Recording');
      startBtn.disabled = true;
      stopBtn.disabled = false;
      showWave('Recording… (audio is being captured)');
      uploadBtn.disabled = true;
    };
    recorder.onstop = () => {
      updateStatus('Stopped');
      startBtn.disabled = false;
      stopBtn.disabled = true;
      showWave('Recording stopped. Ready to upload.');
      uploadBtn.disabled = recordedChunks.length === 0;
    };

    recorder.start(1000); // chunk every 1s
    startSpeechRecognition();
  }

  function stopRecording(){
    if(recorder && recorder.state !== 'inactive') recorder.stop();
    if(mediaStream){
      mediaStream.getTracks().forEach(t => t.stop());
      mediaStream = null;
    }
    stopSpeechRecognition();
  }

  // Web Speech API
  function startSpeechRecognition(){
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if(!SpeechRecognition) {
      appendToParagraph("[Browser does not support Web Speech API — transcripts will be uploaded for server-side transcription]");
      return;
    }
    if(recognition) return;

    recognition = new SpeechRecognition();
    recognition.interimResults = false;   // only final results (avoid duplicates)
    recognition.continuous = true;
    recognition.lang = 'en-US';

    recognition.onstart = ()=>{ console.log('Speech recognition started'); };
    recognition.onerror = (ev)=>{ console.warn('Speech recognition error',ev); };
    recognition.onend = ()=>{
      // if still recording, restart (some browsers stop periodically)
      if(recorder && recorder.state === 'recording'){
        try{ recognition.start(); }catch(e){ console.warn('restart recognition failed',e); }
      }
    };
    recognition.onresult = (evt)=>{
      for(let i=evt.resultIndex;i<evt.results.length;i++){
        if(evt.results[i].isFinal){
          const text = evt.results[i][0].transcript;
          appendToParagraph(text);
        }
      }
    };
    try{ recognition.start(); }catch(e){ console.warn('Recognition start failed',e); }
  }

  function stopSpeechRecognition(){
    if(recognition){
      try{ recognition.onend = null; recognition.stop(); }catch(e){}
      recognition = null;
    }
  }

  // get meeting & owner from querystring
  function qsParam(name){ const u = new URL(location.href); return u.searchParams.get(name) || ""; }
  const meetingParam = decodeURIComponent(qsParam('meeting') || qsParam('meeting'.toLowerCase()) || '');
  const ownerParam   = decodeURIComponent(qsParam('owner') || qsParam('owner'.toLowerCase()) || '');

  async function uploadRecording(){
    if(recordedChunks.length === 0){
      alert('No audio recorded yet.');
      return;
    }
    updateStatus('Uploading audio & transcript...');
    showWave('Uploading…');
    const blob = new Blob(recordedChunks, { type: 'audio/webm' });

    // Build the JSON payload expected by your /upload-recording endpoint:
    // { meeting, owner, participant_email, transcript, final }
    const payload = {
      meeting: meetingParam || '',
      owner: ownerParam || '',
      participant_email: ownerParam || 'unknown',
      transcript: (liveTranscript || "").trim(),
      final: true
    };

    // We'll upload audio as multipart first (so server still gets audio file), but your app's /upload-recording accepts JSON OR multipart.
    // Use form with 'audio' + JSON fields so server will accept the audio and transcript.
    const form = new FormData();
    form.append('meeting', payload.meeting);
    form.append('owner', payload.owner);
    form.append('participant_email', payload.participant_email);
    form.append('transcript', payload.transcript);
    form.append('final', 'true');
    form.append('audio', blob, 'meeting_recording.webm');

    try{
      const resp = await fetch(APP_BASE + '/upload-recording', { method:'POST', body: form });
      const j = await resp.json();
      if(!resp.ok){
        throw new Error(JSON.stringify(j));
      }
      updateStatus('Upload complete');
      showWave('Upload successful.');
      // server returns mom_link and mom record — show link & button
      if(j.mom_link){
        momHint.style.display = 'block';
        momHint.innerHTML = 'MoM (may be available shortly): <a class="momlink" href="'+j.mom_link+'" target="_blank">'+j.mom_link+'</a>';
        openMomBtn.style.display = 'inline-block';
        openMomBtn.onclick = ()=>{ window.open(j.mom_link, '_blank'); };
      } else if(j.mom && j.mom.id){
        const mlink = APP_BASE + '/mom/' + j.mom.id;
        momHint.style.display = 'block';
        momHint.innerHTML = 'MoM: <a class="momlink" href="'+mlink+'" target="_blank">'+mlink+'</a>';
        openMomBtn.style.display = 'inline-block';
        openMomBtn.onclick = ()=>{ window.open(mlink, '_blank'); };
      } else {
        momHint.style.display = 'block';
        momHint.innerText = 'Upload succeeded — but no MoM link returned (server may generate shortly).';
      }
      alert('Upload successful.');
    }catch(err){
      updateStatus('Upload failed');
      showWave('Upload failed — check console and server logs.');
      console.error(err);
      alert('Upload failed: ' + (err.message || err));
    }
  }

  async function autoStart(){
    try{
      await startRecording();
    }catch(e){
      console.log('Auto-start blocked:', e);
      updateStatus('Click Start Recording to enable mic');
      showWave('Auto-start blocked by browser — please click Start.');
      startBtn.disabled = false;
    }
  }

  startBtn.addEventListener('click', async ()=>{
    startBtn.disabled = true;
    try{ await startRecording(); } catch(err){ startBtn.disabled = false; console.error(err); }
  });
  stopBtn.addEventListener('click', ()=>{ stopRecording(); });
  uploadBtn.addEventListener('click', ()=>uploadRecording());

  // Show Open MoM if URL already has a mom id (same page used by redirect)
  const existingMom = qsParam('mom');
  if(existingMom){
    openMomBtn.style.display = 'inline-block';
    openMomBtn.onclick = ()=>{ window.open(APP_BASE + '/mom/' + encodeURIComponent(existingMom), '_blank'); };
    momHint.style.display = 'block';
    momHint.innerHTML = 'MoM: <a class="momlink" href="'+APP_BASE + '/mom/'+encodeURIComponent(existingMom)+'" target="_blank">'+APP_BASE + '/mom/'+encodeURIComponent(existingMom)+'</a>';
  }

  // Enable upload button when we have something to upload
  const enableUploadObserver = new MutationObserver(()=>{
    if(recordedChunks.length > 0 || (liveTranscript && liveTranscript.length>10)){
      uploadBtn.disabled = false;
    }
  });
  enableUploadObserver.observe(transcriptEl, { childList:true, subtree:true, characterData:true });

  // Attempt auto-start (some browsers require user gesture)
  setTimeout(autoStart, 700);
})();
</script>
</body>
</html>
