<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Recorder — AI Meeting Scheduler</title>
  <style>
    /* Full-page, Teams-friendly, centered frame */
    :root {
      --bg: #f6f8fb;
      --card: #fff;
      --accent: #6f46f6;
      --muted: #6b7280;
      --radius: 14px;
      --maxwidth: 1100px;
    }
    html,body { height:100%; margin:0; font-family:Inter,system-ui,Segoe UI,Roboto,"Helvetica Neue",Arial; background:var(--bg); color:#111; }
    .wrap { min-height:100%; display:flex; align-items:center; justify-content:center; padding:32px; box-sizing:border-box; }
    .card { width:100%; max-width:var(--maxwidth); background:var(--card); border-radius:var(--radius); padding:28px; box-shadow:0 6px 30px rgba(23,25,33,0.06); }
    .header { display:flex; align-items:center; gap:12px; margin-bottom:16px; }
    .logo { width:56px; height:56px; border-radius:10px; background:linear-gradient(135deg,#6f46f6,#b794f4); display:flex; align-items:center; justify-content:center; color:white; font-weight:700; font-size:18px; }
    h1 { margin:0; font-size:20px; }
    p.lead { margin:6px 0 18px; color:var(--muted); font-size:14px; }
    .controls { display:flex; gap:12px; align-items:center; margin-bottom:18px; }
    button { padding:10px 16px; border-radius:10px; border:0; cursor:pointer; font-weight:600; }
    .btn-primary { background:var(--accent); color:white; }
    .btn-ghost { background:transparent; color:var(--accent); border:1px solid rgba(111,70,246,0.12); }
    .status { color:var(--muted); font-size:13px; }
    .wave { width:100%; height:86px; background:linear-gradient(180deg,#f8fafc,#fff); border-radius:10px; border:1px dashed #e6e9ef; display:flex; align-items:center; justify-content:center; color:#9aa3b2; margin-bottom:18px; padding:8px; text-align:center; }
    .transcript { max-height:260px; overflow:auto; padding:12px; background:#fafbff; border-radius:10px; border:1px solid #eef2ff; color:#111; font-size:14px; line-height:1.45; white-space:pre-wrap; }
    .muted { color:var(--muted); font-size:13px; }
    .small { font-size:12px; color:#7b7f86; }
    a.momlink { display:inline-block; margin-top:10px; color:var(--accent); text-decoration:none; font-weight:600; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card" role="main">
      <div class="header">
        <div class="logo">TS</div>
        <div>
          <h1>Meeting Recorder</h1>
          <p class="lead">Automatically records meeting audio and generates transcript / MoM. Auto-starts when possible — click to give microphone permission if required.</p>
        </div>
      </div>

      <div class="controls">
        <button id="btnStart" class="btn-primary">Start Recording</button>
        <button id="btnStop" class="btn-ghost" disabled>Stop</button>
        <div style="flex:1"></div>
        <div class="status" id="status">Idle</div>
      </div>

      <div class="wave" id="wave">Mic status: waiting for input…</div>

      <div class="muted">Live Transcript</div>
      <div class="transcript" id="transcript">No transcript yet.</div>

      <div style="height:14px;"></div>
      <div class="muted">Upload / Save</div>
      <div style="margin-top:10px;">
        <button id="uploadBtn" class="btn-ghost" disabled>Upload Audio & Transcript</button>
        <div id="uploadResult" class="small" style="margin-top:8px;"></div>
      </div>
    </div>
  </div>

<script>
/* Recorder + Transcription Script
   - Auto-attempts start on load
   - Uses audio constraints with echoCancellation/noiseSuppression/autoGainControl
   - Single MediaRecorder instance and Web Speech Recognition
   - Dedupe logic to avoid repeated phrases
   - Posts form to /upload-recording with fields: audio, transcript, meeting, owner, participant_email
*/
(async function(){
  const statusEl = document.getElementById('status');
  const startBtn = document.getElementById('btnStart');
  const stopBtn = document.getElementById('btnStop');
  const wave = document.getElementById('wave');
  const transcriptEl = document.getElementById('transcript');
  const uploadBtn = document.getElementById('uploadBtn');
  const uploadResult = document.getElementById('uploadResult');

  let mediaStream = null;
  let recorder = null;
  let recordedChunks = [];
  let recognition = null;
  let liveTranscript = "";
  let lastRecognized = ""; // for dedupe
  const APP_BASE = (window.APP_BASE_URL || '').replace(/\/$/,'') || location.origin;

  // Parse URL params for meeting/owner/participant
  const urlParams = new URLSearchParams(window.location.search);
  const meetingParam = urlParams.get('meeting') || urlParams.get('q') || '';
  const ownerParam = urlParams.get('owner') || '';
  const participantParam = urlParams.get('participant') || ownerParam || '';

  // audio constraints optimized for meetings
  const constraints = {
    audio: {
      echoCancellation: true,
      noiseSuppression: true,
      autoGainControl: true,
      channelCount: 1,
      sampleRate: 44100
    }
  };

  function updateStatus(t){
    statusEl.textContent = t;
  }

  function showWave(msg){
    wave.textContent = msg;
  }

  function appendTranscript(t){
    if(!t) return;
    const cleaned = t.trim();
    if(!cleaned) return;
    const normalized = cleaned.toLowerCase().replace(/\s+/g,' ');
    // simple dedupe
    if(normalized === lastRecognized) return;
    const deduped = dedupeRepeatedWords(normalized);
    lastRecognized = deduped;
    if(transcriptEl.textContent === "No transcript yet.") transcriptEl.textContent = deduped;
    else transcriptEl.textContent += "\n\n" + deduped;
    // store for upload
    liveTranscript += (liveTranscript ? "\n" : "") + deduped;
  }

  function dedupeRepeatedWords(s){
    return s.split(' ').filter((w,i,arr) => !(i>0 && arr[i-1]===w)).join(' ');
  }

  // Start mic + media recorder
  async function startRecording(){
    updateStatus('Requesting microphone...');
    try{
      mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
    }catch(err){
      updateStatus('Microphone permission required.');
      showWave('Click "Start Recording" to give mic permission.');
      throw err;
    }

    if(recorder){ recorder.stop(); recorder = null; }

    recordedChunks = [];
    recorder = new MediaRecorder(mediaStream, { mimeType: 'audio/webm;codecs=opus' });
    recorder.ondataavailable = e => {
      if(e.data && e.data.size > 0) recordedChunks.push(e.data);
    };
    recorder.onstart = () => {
      updateStatus('Recording');
      startBtn.disabled = true;
      stopBtn.disabled = false;
      uploadBtn.disabled = true;
      showWave('Recording… (audio is being captured)');
    };
    recorder.onstop = () => {
      updateStatus('Stopped');
      startBtn.disabled = false;
      stopBtn.disabled = true;
      showWave('Recording stopped. Ready to upload.');
      uploadBtn.disabled = false;
    };

    recorder.start(1000); // collect chunks every 1s
    startSpeechRecognition();
  }

  function stopRecording(){
    if(recorder && recorder.state !== 'inactive') recorder.stop();
    if(mediaStream){
      mediaStream.getTracks().forEach(t => t.stop());
      mediaStream = null;
    }
    stopSpeechRecognition();
  }

  // Web Speech API recognition with single instance
  function startSpeechRecognition(){
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if(!SpeechRecognition) {
      appendTranscript("[Browser does not support Web Speech API — transcripts will be uploaded for server-side transcription]");
      return;
    }
    if(recognition) { return; }

    recognition = new SpeechRecognition();
    recognition.interimResults = false;
    recognition.continuous = true;
    recognition.lang = 'en-US';

    recognition.onstart = () => { console.log('Speech recognition started'); }
    recognition.onerror = (ev) => { console.warn('Speech recognition error', ev); }
    recognition.onend = () => {
      if(recorder && recorder.state === 'recording') {
        try { recognition.start(); } catch(e){ console.warn('restart recognition failed',e); }
      }
    };

    recognition.onresult = (evt) => {
      for(let i=evt.resultIndex; i<evt.results.length; ++i){
        if(evt.results[i].isFinal){
          const text = evt.results[i][0].transcript;
          appendTranscript(text);
        }
      }
    };

    try{
      recognition.start();
    }catch(e){
      console.warn('Recognition start failed', e);
    }
  }

  function stopSpeechRecognition(){
    if(recognition){
      try { recognition.onend = null; recognition.stop(); } catch(e){}
      recognition = null;
    }
  }

  // Upload endpoint: matches backend /upload-recording
  async function uploadRecording(){
    if(recordedChunks.length === 0 && !liveTranscript){
      alert('No audio or transcript to upload.');
      return;
    }

    updateStatus('Uploading audio & transcript...');
    uploadResult.textContent = '';

    const blob = recordedChunks.length ? new Blob(recordedChunks, { type: 'audio/webm' }) : null;
    const form = new FormData();

    if(blob) form.append('audio', blob, 'meeting_recording.webm');   // backend expects 'audio'
    form.append('transcript', liveTranscript || '');
    // include meeting/owner/participant if present
    if(meetingParam) form.append('meeting', meetingParam);
    if(ownerParam) form.append('owner', ownerParam);
    if(participantParam) form.append('participant_email', participantParam);

    try{
      const url = APP_BASE + '/upload-recording';
      console.log('Uploading to', url, 'with meeting=', meetingParam, 'owner=', ownerParam);
      const resp = await fetch(url, {
        method: 'POST',
        body: form
      });

      const contentType = resp.headers.get('content-type') || '';
      let data = null;
      if(contentType.includes('application/json')){
        data = await resp.json();
      } else {
        // fallback to text
        data = { detail: await resp.text() };
      }

      if(!resp.ok){
        const msg = (data && (data.detail || data.error || JSON.stringify(data))) || ('HTTP ' + resp.status);
        updateStatus('Upload failed');
        uploadResult.textContent = 'Upload failed: ' + msg;
        console.error('Upload failed', resp.status, data);
        alert('Upload failed: ' + msg);
        return;
      }

      updateStatus('Upload complete');
      uploadResult.textContent = 'Upload complete.';
      console.log('Upload success', data);

      // If moment-of-meeting link returned, open it
      if(data && data.mom_link){
        const link = data.mom_link;
        uploadResult.innerHTML = 'MoM: <a class="momlink" target="_blank" rel="noopener" href="' + link + '">' + link + '</a>';
        // open in a new tab automatically
        window.open(link, '_blank');
      } else {
        alert('Upload successful.');
      }
    }catch(err){
      updateStatus('Upload failed: ' + (err.message||err));
      console.error('Upload error', err);
      uploadResult.textContent = 'Upload error: ' + (err.message||err);
      alert('Upload failed: ' + (err.message||err));
    }
  }

  // Auto-start attempt on page load
  async function autoStart(){
    try{
      await startRecording();
    }catch(e){
      console.log('Auto-start blocked:', e);
      updateStatus('Click Start Recording to enable mic');
      showWave('Auto-start blocked by browser — please click Start.');
      startBtn.disabled = false;
    }
  }

  // Hook up UI
  startBtn.addEventListener('click', async (e) => {
    startBtn.disabled = true;
    try {
      await startRecording();
    } catch(err) {
      startBtn.disabled = false;
      console.error(err);
    }
  });

  stopBtn.addEventListener('click', (e) => {
    stopRecording();
  });

  uploadBtn.addEventListener('click', (e) => {
    uploadRecording();
  });

  // Try auto-start after small delay
  setTimeout(autoStart, 700);

})();
</script>
</body>
</html>
