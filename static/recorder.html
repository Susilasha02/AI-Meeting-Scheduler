<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Recorder — AI Meeting Scheduler</title>
  <style>
    /* Full-page, Teams-friendly, centered frame */
    :root {
      --bg: #f6f8fb;
      --card: #fff;
      --accent: #6f46f6;
      --muted: #6b7280;
      --radius: 14px;
      --maxwidth: 1100px;
    }
    html,body { height:100%; margin:0; font-family:Inter,system-ui,Segoe UI,Roboto,"Helvetica Neue",Arial; background:var(--bg); color:#111; }
    .wrap { min-height:100%; display:flex; align-items:center; justify-content:center; padding:32px; box-sizing:border-box; }
    .card { width:100%; max-width:var(--maxwidth); background:var(--card); border-radius:var(--radius); padding:28px; box-shadow:0 6px 30px rgba(23,25,33,0.06); }
    .header { display:flex; align-items:center; gap:12px; margin-bottom:16px; }
    .logo { width:56px; height:56px; border-radius:10px; background:linear-gradient(135deg,#6f46f6,#b794f4); display:flex; align-items:center; justify-content:center; color:white; font-weight:700; font-size:18px; }
    h1 { margin:0; font-size:20px; }
    p.lead { margin:6px 0 18px; color:var(--muted); font-size:14px; }
    .controls { display:flex; gap:12px; align-items:center; margin-bottom:18px; }
    button { padding:10px 16px; border-radius:10px; border:0; cursor:pointer; font-weight:600; }
    .btn-primary { background:var(--accent); color:white; }
    .btn-ghost { background:transparent; color:var(--accent); border:1px solid rgba(111,70,246,0.12); }
    .status { color:var(--muted); font-size:13px; }
    .wave { width:100%; height:86px; background:linear-gradient(180deg,#f8fafc,#fff); border-radius:10px; border:1px dashed #e6e9ef; display:flex; align-items:center; justify-content:center; color:#9aa3b2; margin-bottom:18px; }
    .transcript { max-height:260px; overflow:auto; padding:12px; background:#fafbff; border-radius:10px; border:1px solid #eef2ff; color:#111; font-size:14px; line-height:1.45; }
    .muted { color:var(--muted); font-size:13px; }
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card" role="main">
      <div class="header">
        <div class="logo">TS</div>
        <div>
          <h1>Meeting Recorder</h1>
          <p class="lead">Automatically records meeting audio and generates transcript / MoM. Auto-starts when possible — click to give microphone permission if required.</p>
        </div>
      </div>

      <div class="controls">
        <button id="btnStart" class="btn-primary">Start Recording</button>
        <button id="btnStop" class="btn-ghost" disabled>Stop</button>
        <div class="status" id="status">Idle</div>
      </div>

      <div class="wave" id="wave">Mic status: waiting for input…</div>

      <div class="muted">Live Transcript</div>
      <div class="transcript" id="transcript">No transcript yet.</div>

      <div style="height:14px;"></div>
      <div class="muted">Upload / Save</div>
      <div style="margin-top:10px;">
        <button id="uploadBtn" class="btn-ghost" disabled>Upload Audio & Transcript</button>
      </div>
    </div>
  </div>

<script>
/* Recorder + Transcription Script
   - Auto-attempts start on load
   - Uses audio constraints with echoCancellation/noiseSuppression/autoGainControl
   - Single MediaRecorder instance and single Web Speech Recognition
   - Simple dedupe logic to avoid repeated phrases
*/
(async function(){
  const statusEl = document.getElementById('status');
  const startBtn = document.getElementById('btnStart');
  const stopBtn = document.getElementById('btnStop');
  const wave = document.getElementById('wave');
  const transcriptEl = document.getElementById('transcript');
  const uploadBtn = document.getElementById('uploadBtn');

  let mediaStream = null;
  let recorder = null;
  let recordedChunks = [];
  let recognition = null;
  let liveTranscript = "";
  let lastRecognized = ""; // for dedupe
  const APP_BASE = (window.APP_BASE_URL || '').replace(/\/$/,'') || location.origin;

  // audio constraints optimized for meetings
  const constraints = {
    audio: {
      echoCancellation: true,
      noiseSuppression: true,
      autoGainControl: true,
      channelCount: 1,
      sampleRate: 44100
    }
  };

  function updateStatus(t){
    statusEl.textContent = t;
  }

  function showWave(msg){
    wave.textContent = msg;
  }

  function appendTranscript(t){
    if(!t) return;
    // simple dedupe: ignore if very similar to last recognized chunk
    const cleaned = t.trim();
    if(!cleaned) return;
    const normalized = cleaned.toLowerCase().replace(/\s+/g,' ');
    if(normalized === lastRecognized) return;
    // avoid repeating short filler repeats (e.g., "okay okay")
    const deduped = dedupeRepeatedWords(normalized);
    lastRecognized = deduped;
    if(transcriptEl.textContent === "No transcript yet.") transcriptEl.textContent = deduped;
    else transcriptEl.textContent += "\n\n" + deduped;
    // store for upload
    liveTranscript += (liveTranscript ? "\n" : "") + deduped;
  }

  // remove immediate repeated tokens like "hello hello" or "this is is"
  function dedupeRepeatedWords(s){
    return s.split(' ').filter((w,i,arr) => !(i>0 && arr[i-1]===w)).join(' ');
  }

  // Start mic + media recorder
  async function startRecording(){
    updateStatus('Requesting microphone...');
    try{
      mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
    }catch(err){
      updateStatus('Microphone permission required.');
      showWave('Click "Start Recording" to give mic permission.');
      throw err;
    }

    // ensure only one recorder instance
    if(recorder){ recorder.stop(); recorder = null; }

    recordedChunks = [];
    recorder = new MediaRecorder(mediaStream, { mimeType: 'audio/webm;codecs=opus' });
    recorder.ondataavailable = e => {
      if(e.data && e.data.size > 0) recordedChunks.push(e.data);
    };
    recorder.onstart = () => {
      updateStatus('Recording');
      startBtn.disabled = true;
      stopBtn.disabled = false;
      showWave('Recording… (audio is being captured)');
    };
    recorder.onstop = () => {
      updateStatus('Stopped');
      startBtn.disabled = false;
      stopBtn.disabled = true;
      showWave('Recording stopped. Ready to upload.');
      uploadBtn.disabled = false;
    };

    recorder.start(1000); // collect chunks every 1s
    startSpeechRecognition();
  }

  function stopRecording(){
    if(recorder && recorder.state !== 'inactive') recorder.stop();
    if(mediaStream){
      mediaStream.getTracks().forEach(t => t.stop());
      mediaStream = null;
    }
    stopSpeechRecognition();
  }

  // Web Speech API recognition with single instance
  function startSpeechRecognition(){
    // Web Speech API guard
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if(!SpeechRecognition) {
      appendTranscript("[Browser does not support Web Speech API — transcripts will be uploaded for server-side transcription]");
      return;
    }

    if(recognition) { /* already running */ return; }

    recognition = new SpeechRecognition();
    recognition.interimResults = false; // final results only (avoid duplicate interim)
    recognition.continuous = true;      // continuous listening
    recognition.lang = 'en-US';         // change if needed

    recognition.onstart = () => { console.log('Speech recognition started'); }
    recognition.onerror = (ev) => { console.warn('Speech recognition error', ev); }
    recognition.onend = () => {
      // if recording is still active, restart recognition (handles bugs)
      if(recorder && recorder.state === 'recording') {
        try { recognition.start(); } catch(e){ console.warn('restart recognition failed',e); }
      }
    };

    recognition.onresult = (evt) => {
      // accumulate final results
      for(let i=evt.resultIndex; i<evt.results.length; ++i){
        if(evt.results[i].isFinal){
          const text = evt.results[i][0].transcript;
          appendTranscript(text);
        }
      }
    };

    try{
      recognition.start();
    }catch(e){
      console.warn('Recognition start failed', e);
    }
  }

  function stopSpeechRecognition(){
    if(recognition){
      try { recognition.onend = null; recognition.stop(); } catch(e){}
      recognition = null;
    }
  }

  // Upload endpoint: adapt to your backend path
  async function uploadRecording(){
    if(recordedChunks.length === 0){
      alert('No audio recorded yet.');
      return;
    }
    updateStatus('Uploading audio & transcript...');
    const blob = new Blob(recordedChunks, { type: 'audio/webm' });
    const form = new FormData();
    form.append('file', blob, 'meeting_recording.webm');
    form.append('transcript', liveTranscript);

    try{
      // uses your existing upload endpoint; adapt path if different
      const resp = await fetch(APP_BASE + '/upload-audio', {
        method: 'POST',
        body: form
      });
      if(!resp.ok) throw new Error(await resp.text());
      updateStatus('Upload complete');
      alert('Upload successful.');
    }catch(err){
      updateStatus('Upload failed: ' + (err.message||err));
      console.error(err);
      alert('Upload failed: ' + (err.message||err));
    }
  }

  // Auto-start attempt on page load
  async function autoStart(){
    // some browsers require user gesture; we still attempt
    try{
      await startRecording();
    }catch(e){
      console.log('Auto-start blocked:', e);
      updateStatus('Click Start Recording to enable mic'); // user visible
      showWave('Auto-start blocked by browser — please click Start.');
      startBtn.disabled = false;
    }
  }

  // Hook up UI
  startBtn.addEventListener('click', async (e) => {
    startBtn.disabled = true;
    try {
      await startRecording();
    } catch(err) {
      startBtn.disabled = false;
      console.error(err);
    }
  });

  stopBtn.addEventListener('click', (e) => {
    stopRecording();
  });

  uploadBtn.addEventListener('click', (e) => {
    uploadRecording();
  });

  // Try auto-start
  // Wait a tick so Teams/iframe has a chance to focus
  setTimeout(autoStart, 700);

})();
</script>
</body>
</html>
